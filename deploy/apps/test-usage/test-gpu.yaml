apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  runtimeClassName: nvidia
  nodeName: drs-node01
  restartPolicy: OnFailure
  containers:
    - name: cuda-container
      image: 192.168.3.129/kubernetes/gpu_mem_alloc:0.0.1
      args:
        - -m
        - "146" # CUDA allocate 154 MB VRAM
        - -t
        - "120"
      resources:
        requests:
          nvidia.com/gpu: 1
        limits:
          nvidia.com/gpu: 1